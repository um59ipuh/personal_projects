{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6faaa552-0a75-4242-b240-015e77930a6a",
   "metadata": {},
   "source": [
    "## Process :: Loading docs & credentials -> Indexing -> retrieval -> updating"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f1f0de-6493-49d6-8040-2d201e37bb7b",
   "metadata": {},
   "source": [
    "### Imstalling and importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51eec853-13e2-40af-b0e3-fa904361334b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "39bb2b2c-f401-494b-a7a3-8370972e64bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain_community in /opt/anaconda3/lib/python3.11/site-packages (0.0.31)\n",
      "Requirement already satisfied: tiktoken in /opt/anaconda3/lib/python3.11/site-packages (0.6.0)\n",
      "Requirement already satisfied: langchain-openai in /opt/anaconda3/lib/python3.11/site-packages (0.1.1)\n",
      "Requirement already satisfied: langchainhub in /opt/anaconda3/lib/python3.11/site-packages (0.1.15)\n",
      "Requirement already satisfied: chromadb in /opt/anaconda3/lib/python3.11/site-packages (0.4.24)\n",
      "Requirement already satisfied: langchain in /opt/anaconda3/lib/python3.11/site-packages (0.1.14)\n",
      "Requirement already satisfied: openai in /opt/anaconda3/lib/python3.11/site-packages (1.16.1)\n",
      "Requirement already satisfied: jq in /opt/anaconda3/lib/python3.11/site-packages (1.7.0)\n",
      "Requirement already satisfied: trulens-eval in /opt/anaconda3/lib/python3.11/site-packages (0.27.2)\n",
      "Requirement already satisfied: pydantic in /opt/anaconda3/lib/python3.11/site-packages (2.6.4)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/anaconda3/lib/python3.11/site-packages (from langchain_community) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/anaconda3/lib/python3.11/site-packages (from langchain_community) (2.0.25)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/anaconda3/lib/python3.11/site-packages (from langchain_community) (3.9.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/anaconda3/lib/python3.11/site-packages (from langchain_community) (0.6.4)\n",
      "Requirement already satisfied: langchain-core<0.2.0,>=0.1.37 in /opt/anaconda3/lib/python3.11/site-packages (from langchain_community) (0.1.39)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /opt/anaconda3/lib/python3.11/site-packages (from langchain_community) (0.1.39)\n",
      "Requirement already satisfied: numpy<2,>=1 in /opt/anaconda3/lib/python3.11/site-packages (from langchain_community) (1.26.4)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/anaconda3/lib/python3.11/site-packages (from langchain_community) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /opt/anaconda3/lib/python3.11/site-packages (from langchain_community) (8.2.3)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/anaconda3/lib/python3.11/site-packages (from tiktoken) (2023.10.3)\n",
      "Requirement already satisfied: types-requests<3.0.0.0,>=2.31.0.2 in /opt/anaconda3/lib/python3.11/site-packages (from langchainhub) (2.31.0.20240403)\n",
      "Requirement already satisfied: build>=1.0.3 in /opt/anaconda3/lib/python3.11/site-packages (from chromadb) (1.2.1)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.3 in /opt/anaconda3/lib/python3.11/site-packages (from chromadb) (0.7.3)\n",
      "Requirement already satisfied: fastapi>=0.95.2 in /opt/anaconda3/lib/python3.11/site-packages (from chromadb) (0.110.1)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in /opt/anaconda3/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.29.0)\n",
      "Requirement already satisfied: posthog>=2.4.0 in /opt/anaconda3/lib/python3.11/site-packages (from chromadb) (3.5.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /opt/anaconda3/lib/python3.11/site-packages (from chromadb) (4.9.0)\n",
      "Requirement already satisfied: pulsar-client>=3.1.0 in /opt/anaconda3/lib/python3.11/site-packages (from chromadb) (3.4.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in /opt/anaconda3/lib/python3.11/site-packages (from chromadb) (1.16.3)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in /opt/anaconda3/lib/python3.11/site-packages (from chromadb) (1.24.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /opt/anaconda3/lib/python3.11/site-packages (from chromadb) (1.24.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /opt/anaconda3/lib/python3.11/site-packages (from chromadb) (0.45b0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /opt/anaconda3/lib/python3.11/site-packages (from chromadb) (1.24.0)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /opt/anaconda3/lib/python3.11/site-packages (from chromadb) (0.15.2)\n",
      "Requirement already satisfied: pypika>=0.48.9 in /opt/anaconda3/lib/python3.11/site-packages (from chromadb) (0.48.9)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in /opt/anaconda3/lib/python3.11/site-packages (from chromadb) (4.66.2)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /opt/anaconda3/lib/python3.11/site-packages (from chromadb) (7.4.0)\n",
      "Requirement already satisfied: importlib-resources in /opt/anaconda3/lib/python3.11/site-packages (from chromadb) (6.4.0)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /opt/anaconda3/lib/python3.11/site-packages (from chromadb) (1.62.1)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in /opt/anaconda3/lib/python3.11/site-packages (from chromadb) (4.1.2)\n",
      "Requirement already satisfied: typer>=0.9.0 in /opt/anaconda3/lib/python3.11/site-packages (from chromadb) (0.12.1)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in /opt/anaconda3/lib/python3.11/site-packages (from chromadb) (29.0.0)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in /opt/anaconda3/lib/python3.11/site-packages (from chromadb) (4.1.0)\n",
      "Requirement already satisfied: orjson>=3.9.12 in /opt/anaconda3/lib/python3.11/site-packages (from chromadb) (3.10.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/anaconda3/lib/python3.11/site-packages (from langchain) (1.33)\n",
      "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /opt/anaconda3/lib/python3.11/site-packages (from langchain) (0.0.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/anaconda3/lib/python3.11/site-packages (from openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/anaconda3/lib/python3.11/site-packages (from openai) (1.8.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/anaconda3/lib/python3.11/site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/lib/python3.11/site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: frozendict>=2.3.8 in /opt/anaconda3/lib/python3.11/site-packages (from trulens-eval) (2.4.1)\n",
      "Requirement already satisfied: munch>=3.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from trulens-eval) (4.0.0)\n",
      "Requirement already satisfied: dill>=0.3.7 in /opt/anaconda3/lib/python3.11/site-packages (from trulens-eval) (0.3.7)\n",
      "Requirement already satisfied: nltk>=3.8.1 in /opt/anaconda3/lib/python3.11/site-packages (from trulens-eval) (3.8.1)\n",
      "Requirement already satisfied: nest-asyncio>=1.5.8 in /opt/anaconda3/lib/python3.11/site-packages (from trulens-eval) (1.6.0)\n",
      "Requirement already satisfied: psutil>=5.9.8 in /opt/anaconda3/lib/python3.11/site-packages (from trulens-eval) (5.9.8)\n",
      "Requirement already satisfied: pip>=24.0 in /opt/anaconda3/lib/python3.11/site-packages (from trulens-eval) (24.0)\n",
      "Requirement already satisfied: packaging>=23.2 in /opt/anaconda3/lib/python3.11/site-packages (from trulens-eval) (23.2)\n",
      "Requirement already satisfied: python-dotenv>=1.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from trulens-eval) (1.0.1)\n",
      "Requirement already satisfied: merkle-json>=1.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from trulens-eval) (1.0.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /opt/anaconda3/lib/python3.11/site-packages (from trulens-eval) (0.9.0)\n",
      "Requirement already satisfied: millify>=0.1.1 in /opt/anaconda3/lib/python3.11/site-packages (from trulens-eval) (0.1.1)\n",
      "Requirement already satisfied: humanize>=4.6.0 in /opt/anaconda3/lib/python3.11/site-packages (from trulens-eval) (4.9.0)\n",
      "Requirement already satisfied: streamlit>=1.32.2 in /opt/anaconda3/lib/python3.11/site-packages (from trulens-eval) (1.33.0)\n",
      "Requirement already satisfied: streamlit-aggrid==0.3.4 in /opt/anaconda3/lib/python3.11/site-packages (from trulens-eval) (0.3.4)\n",
      "Requirement already satisfied: streamlit-extras>=0.4.0 in /opt/anaconda3/lib/python3.11/site-packages (from trulens-eval) (0.4.2)\n",
      "Requirement already satisfied: rich>=13.6.0 in /opt/anaconda3/lib/python3.11/site-packages (from trulens-eval) (13.7.1)\n",
      "Requirement already satisfied: alembic>=1.11.2 in /opt/anaconda3/lib/python3.11/site-packages (from trulens-eval) (1.13.1)\n",
      "Requirement already satisfied: pandas>=1.2 in /opt/anaconda3/lib/python3.11/site-packages (from streamlit-aggrid==0.3.4->trulens-eval) (2.1.4)\n",
      "Requirement already satisfied: python-decouple<4.0,>=3.6 in /opt/anaconda3/lib/python3.11/site-packages (from streamlit-aggrid==0.3.4->trulens-eval) (3.8)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/anaconda3/lib/python3.11/site-packages (from pydantic) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in /opt/anaconda3/lib/python3.11/site-packages (from pydantic) (2.16.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.9.3)\n",
      "Requirement already satisfied: Mako in /opt/anaconda3/lib/python3.11/site-packages (from alembic>=1.11.2->trulens-eval) (1.3.2)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/anaconda3/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: pyproject_hooks in /opt/anaconda3/lib/python3.11/site-packages (from build>=1.0.3->chromadb) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/anaconda3/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.21.1)\n",
      "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in /opt/anaconda3/lib/python3.11/site-packages (from fastapi>=0.95.2->chromadb) (0.37.2)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/anaconda3/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/anaconda3/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.1)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/anaconda3/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /opt/anaconda3/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /opt/anaconda3/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (2.29.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /opt/anaconda3/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (0.58.0)\n",
      "Requirement already satisfied: requests-oauthlib in /opt/anaconda3/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /opt/anaconda3/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in /opt/anaconda3/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (2.0.7)\n",
      "Requirement already satisfied: click in /opt/anaconda3/lib/python3.11/site-packages (from nltk>=3.8.1->trulens-eval) (8.1.7)\n",
      "Requirement already satisfied: joblib in /opt/anaconda3/lib/python3.11/site-packages (from nltk>=3.8.1->trulens-eval) (1.2.0)\n",
      "Requirement already satisfied: coloredlogs in /opt/anaconda3/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /opt/anaconda3/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb) (24.3.25)\n",
      "Requirement already satisfied: protobuf in /opt/anaconda3/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb) (3.20.3)\n",
      "Requirement already satisfied: sympy in /opt/anaconda3/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb) (1.12)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /opt/anaconda3/lib/python3.11/site-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.14)\n",
      "Requirement already satisfied: importlib-metadata<=7.0,>=6.0 in /opt/anaconda3/lib/python3.11/site-packages (from opentelemetry-api>=1.2.0->chromadb) (7.0.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /opt/anaconda3/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.63.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.24.0 in /opt/anaconda3/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.24.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.24.0 in /opt/anaconda3/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.24.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.45b0 in /opt/anaconda3/lib/python3.11/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.45b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.45b0 in /opt/anaconda3/lib/python3.11/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.45b0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.45b0 in /opt/anaconda3/lib/python3.11/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.45b0)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.45b0 in /opt/anaconda3/lib/python3.11/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.45b0)\n",
      "Requirement already satisfied: setuptools>=16.0 in /opt/anaconda3/lib/python3.11/site-packages (from opentelemetry-instrumentation==0.45b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (68.2.2)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from opentelemetry-instrumentation==0.45b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.14.1)\n",
      "Requirement already satisfied: asgiref~=3.0 in /opt/anaconda3/lib/python3.11/site-packages (from opentelemetry-instrumentation-asgi==0.45b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.8.1)\n",
      "Requirement already satisfied: monotonic>=1.5 in /opt/anaconda3/lib/python3.11/site-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /opt/anaconda3/lib/python3.11/site-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3,>=2->langchain_community) (2.0.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/anaconda3/lib/python3.11/site-packages (from rich>=13.6.0->trulens-eval) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/lib/python3.11/site-packages (from rich>=13.6.0->trulens-eval) (2.15.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/anaconda3/lib/python3.11/site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.0.1)\n",
      "Requirement already satisfied: altair<6,>=4.0 in /opt/anaconda3/lib/python3.11/site-packages (from streamlit>=1.32.2->trulens-eval) (5.0.1)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from streamlit>=1.32.2->trulens-eval) (1.6.2)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in /opt/anaconda3/lib/python3.11/site-packages (from streamlit>=1.32.2->trulens-eval) (4.2.2)\n",
      "Requirement already satisfied: pillow<11,>=7.1.0 in /opt/anaconda3/lib/python3.11/site-packages (from streamlit>=1.32.2->trulens-eval) (10.2.0)\n",
      "Requirement already satisfied: pyarrow>=7.0 in /opt/anaconda3/lib/python3.11/site-packages (from streamlit>=1.32.2->trulens-eval) (14.0.2)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in /opt/anaconda3/lib/python3.11/site-packages (from streamlit>=1.32.2->trulens-eval) (0.10.2)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /opt/anaconda3/lib/python3.11/site-packages (from streamlit>=1.32.2->trulens-eval) (3.1.37)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /opt/anaconda3/lib/python3.11/site-packages (from streamlit>=1.32.2->trulens-eval) (0.8.0)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in /opt/anaconda3/lib/python3.11/site-packages (from streamlit>=1.32.2->trulens-eval) (6.3.3)\n",
      "Requirement already satisfied: entrypoints>=0.4 in /opt/anaconda3/lib/python3.11/site-packages (from streamlit-extras>=0.4.0->trulens-eval) (0.4)\n",
      "Requirement already satisfied: htbuilder>=0.6.2 in /opt/anaconda3/lib/python3.11/site-packages (from streamlit-extras>=0.4.0->trulens-eval) (0.6.2)\n",
      "Requirement already satisfied: markdownlit>=0.0.5 in /opt/anaconda3/lib/python3.11/site-packages (from streamlit-extras>=0.4.0->trulens-eval) (0.0.7)\n",
      "Requirement already satisfied: prometheus-client>=0.14.0 in /opt/anaconda3/lib/python3.11/site-packages (from streamlit-extras>=0.4.0->trulens-eval) (0.14.1)\n",
      "Requirement already satisfied: st-annotated-text>=3.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from streamlit-extras>=0.4.0->trulens-eval) (4.0.1)\n",
      "Requirement already satisfied: streamlit-camera-input-live>=0.2.0 in /opt/anaconda3/lib/python3.11/site-packages (from streamlit-extras>=0.4.0->trulens-eval) (0.2.0)\n",
      "Requirement already satisfied: streamlit-card>=0.0.4 in /opt/anaconda3/lib/python3.11/site-packages (from streamlit-extras>=0.4.0->trulens-eval) (1.0.0)\n",
      "Requirement already satisfied: streamlit-embedcode>=0.1.2 in /opt/anaconda3/lib/python3.11/site-packages (from streamlit-extras>=0.4.0->trulens-eval) (0.1.2)\n",
      "Requirement already satisfied: streamlit-faker>=0.0.2 in /opt/anaconda3/lib/python3.11/site-packages (from streamlit-extras>=0.4.0->trulens-eval) (0.0.3)\n",
      "Requirement already satisfied: streamlit-image-coordinates<0.2.0,>=0.1.1 in /opt/anaconda3/lib/python3.11/site-packages (from streamlit-extras>=0.4.0->trulens-eval) (0.1.6)\n",
      "Requirement already satisfied: streamlit-keyup>=0.1.9 in /opt/anaconda3/lib/python3.11/site-packages (from streamlit-extras>=0.4.0->trulens-eval) (0.2.4)\n",
      "Requirement already satisfied: streamlit-toggle-switch>=1.0.2 in /opt/anaconda3/lib/python3.11/site-packages (from streamlit-extras>=0.4.0->trulens-eval) (1.0.2)\n",
      "Requirement already satisfied: streamlit-vertical-slider>=2.5.5 in /opt/anaconda3/lib/python3.11/site-packages (from streamlit-extras>=0.4.0->trulens-eval) (2.5.5)\n",
      "Requirement already satisfied: validators>=0.20.0 in /opt/anaconda3/lib/python3.11/site-packages (from streamlit-extras>=0.4.0->trulens-eval) (0.28.0)\n",
      "Requirement already satisfied: huggingface_hub<1.0,>=0.16.4 in /opt/anaconda3/lib/python3.11/site-packages (from tokenizers>=0.13.2->chromadb) (0.22.2)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /opt/anaconda3/lib/python3.11/site-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/anaconda3/lib/python3.11/site-packages (from typing-inspect>=0.8.0->trulens-eval) (1.0.0)\n",
      "Requirement already satisfied: httptools>=0.5.0 in /opt/anaconda3/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.1)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /opt/anaconda3/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.19.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /opt/anaconda3/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
      "Requirement already satisfied: websockets>=10.4 in /opt/anaconda3/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (12.0)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.11/site-packages (from altair<6,>=4.0->streamlit>=1.32.2->trulens-eval) (3.1.3)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /opt/anaconda3/lib/python3.11/site-packages (from altair<6,>=4.0->streamlit>=1.32.2->trulens-eval) (4.19.2)\n",
      "Requirement already satisfied: toolz in /opt/anaconda3/lib/python3.11/site-packages (from altair<6,>=4.0->streamlit>=1.32.2->trulens-eval) (0.12.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/anaconda3/lib/python3.11/site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit>=1.32.2->trulens-eval) (4.0.7)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/anaconda3/lib/python3.11/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/anaconda3/lib/python3.11/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
      "Requirement already satisfied: more-itertools in /opt/anaconda3/lib/python3.11/site-packages (from htbuilder>=0.6.2->streamlit-extras>=0.4.0->trulens-eval) (10.1.0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.11/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/lib/python3.11/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2023.10.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/anaconda3/lib/python3.11/site-packages (from importlib-metadata<=7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.17.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=13.6.0->trulens-eval) (0.1.0)\n",
      "Requirement already satisfied: markdown in /opt/anaconda3/lib/python3.11/site-packages (from markdownlit>=0.0.5->streamlit-extras>=0.4.0->trulens-eval) (3.6)\n",
      "Requirement already satisfied: lxml in /opt/anaconda3/lib/python3.11/site-packages (from markdownlit>=0.0.5->streamlit-extras>=0.4.0->trulens-eval) (4.9.3)\n",
      "Requirement already satisfied: favicon in /opt/anaconda3/lib/python3.11/site-packages (from markdownlit>=0.0.5->streamlit-extras>=0.4.0->trulens-eval) (0.7.0)\n",
      "Requirement already satisfied: pymdown-extensions in /opt/anaconda3/lib/python3.11/site-packages (from markdownlit>=0.0.5->streamlit-extras>=0.4.0->trulens-eval) (10.7.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.11/site-packages (from pandas>=1.2->streamlit-aggrid==0.3.4->trulens-eval) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/anaconda3/lib/python3.11/site-packages (from pandas>=1.2->streamlit-aggrid==0.3.4->trulens-eval) (2023.3)\n",
      "Requirement already satisfied: faker in /opt/anaconda3/lib/python3.11/site-packages (from streamlit-faker>=0.0.2->streamlit-extras>=0.4.0->trulens-eval) (24.4.0)\n",
      "Requirement already satisfied: matplotlib in /opt/anaconda3/lib/python3.11/site-packages (from streamlit-faker>=0.0.2->streamlit-extras>=0.4.0->trulens-eval) (3.8.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /opt/anaconda3/lib/python3.11/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /opt/anaconda3/lib/python3.11/site-packages (from Mako->alembic>=1.11.2->trulens-eval) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/anaconda3/lib/python3.11/site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Requirement already satisfied: smmap<5,>=3.0.1 in /opt/anaconda3/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit>=1.32.2->trulens-eval) (4.0.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/anaconda3/lib/python3.11/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=1.32.2->trulens-eval) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/anaconda3/lib/python3.11/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=1.32.2->trulens-eval) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/anaconda3/lib/python3.11/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=1.32.2->trulens-eval) (0.10.6)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/anaconda3/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.8)\n",
      "Requirement already satisfied: beautifulsoup4>=4.7.0 in /opt/anaconda3/lib/python3.11/site-packages (from favicon->markdownlit>=0.0.5->streamlit-extras>=0.4.0->trulens-eval) (4.12.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/lib/python3.11/site-packages (from matplotlib->streamlit-faker>=0.0.2->streamlit-extras>=0.4.0->trulens-eval) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/lib/python3.11/site-packages (from matplotlib->streamlit-faker>=0.0.2->streamlit-extras>=0.4.0->trulens-eval) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/lib/python3.11/site-packages (from matplotlib->streamlit-faker>=0.0.2->streamlit-extras>=0.4.0->trulens-eval) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/anaconda3/lib/python3.11/site-packages (from matplotlib->streamlit-faker>=0.0.2->streamlit-extras>=0.4.0->trulens-eval) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/lib/python3.11/site-packages (from matplotlib->streamlit-faker>=0.0.2->streamlit-extras>=0.4.0->trulens-eval) (3.0.9)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/anaconda3/lib/python3.11/site-packages (from beautifulsoup4>=4.7.0->favicon->markdownlit>=0.0.5->streamlit-extras>=0.4.0->trulens-eval) (2.5)\n"
     ]
    }
   ],
   "source": [
    "! pip install langchain_community tiktoken langchain-openai langchainhub chromadb langchain openai jq trulens-eval pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fea133-037b-426c-8dad-1cf1d4c8f93e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3e55f4e-18e5-44ac-b47e-d04e8df4bbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing\n",
    "from langchain import hub\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26256a8a-86e7-45e8-8919-3d30bd1a02cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "be358bf8-981a-49b4-ac33-b28797935ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# credential loading and set to environment\n",
    "import json\n",
    "def get_credentials(file_path:str=\"credentials.json\"):\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "import os\n",
    "openai_api_key = get_credentials()['openai_api_Key_aweqa']\n",
    "# set key to environment\n",
    "os.environ['OPENAI_API_KEY'] = openai_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e3354c6-215f-465c-b50b-437b8428a2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819f0a20-bf14-4c68-8ab6-1e606f59bba5",
   "metadata": {},
   "source": [
    "### load document -> splitting -> indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "069c16a8-0dd2-4369-88bc-196d67a857b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2580"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "def load_document_as_array(file_path:str = \"./data/scraped_data.jsonl\"):\n",
    "    data = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            json_object = json.loads(line)\n",
    "            data.append(json_object)\n",
    "    return data\n",
    "\n",
    "len(load_document_as_array())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d3abd97-19e9-4635-a821-ef4982dc0eda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': \"Skip to content\\n          (#start-building) \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n  (https://github.com/duneanalytics/docs/edit/master/docs/index.md) \\n Welcome \\n Dune is a web-based platform that allows you to query public blockchain data and aggregate it into beautiful dashboards. \\n \\n Quickstart \\n To get started with Dune in 5 minutes, see the  Quickstart  (quickstart/) . \\n \\n \\n \\n The world's blockchain data at your fingertips! \\n \\n Blockchains are open and transparent, but each chain is uniqueâ€”making it difficult to understand, ingest, and aggregate data. Dune gives you the proper tools to analyze cross-chain data for different tokens, wallets, and protocols. You can also easily share your work with the community. \\n \",\n",
       " 'url': 'https://dune.com/docs/'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(load_document_as_array()[0])\n",
    "load_document_as_array()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "702c6071-1542-463e-9860-51d3eec27692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking is there already exists or not\n",
    "persist_directory = 'vector_db'\n",
    "# embedding \n",
    "embedding = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd264ed-2291-4ac2-b7d4-cf0a253d2130",
   "metadata": {},
   "source": [
    "### load document for splitting and split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a63dd3a8-c421-4325-a210-fae91c4cd348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# meta data function :: add source url as metadata instead of disk path\n",
    "def metadata_func(record: dict, metadata: dict) -> dict:\n",
    "    if \"source\" in metadata:\n",
    "        metadata[\"source\"] = record.get(\"url\")\n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e36fb399-6594-466e-9398-44585cb032f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import JSONLoader for JSON Line loading\n",
    "from langchain_community.document_loaders import JSONLoader\n",
    "\n",
    "loader = JSONLoader(\n",
    "    file_path='./data/scraped_data.jsonl',\n",
    "    jq_schema='.',\n",
    "    text_content=False,\n",
    "    json_lines=True,\n",
    "    metadata_func=metadata_func)\n",
    "\n",
    "document = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "15c72e18-d9f8-491c-a6bb-e3e345502b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=300, \n",
    "    chunk_overlap=50)\n",
    "\n",
    "# Make splits\n",
    "splits = text_splitter.split_documents(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "662f9f68-fb5f-41ef-8a53-ae682479de21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "78a8010d-044d-4014-adeb-d724fba5e204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# indexing and persist\n",
    "persist_directory = 'vector_db'\n",
    "vectorstore = Chroma.from_documents(documents=splits, \n",
    "                                    embedding=OpenAIEmbeddings(),\n",
    "                                    persist_directory=persist_directory)\n",
    "\n",
    "# retriever of vector db\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61eec273-4f1d-4664-8e65-f413a37f8ce7",
   "metadata": {},
   "source": [
    "### Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a7f1a6-d49c-43fa-842b-cf8446c61cd6",
   "metadata": {},
   "source": [
    "#### User input here : change query in user_query variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c6f71028-beb5-4c91-969b-7b921d64b2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the user query here:: edit the user_query variable from here.\n",
    "user_query = \"\"\"We removed the ability to archive queries, and instead added the ability to completely delete them. \n",
    "Update all relevant knowledge\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a2ed37ff-ba72-4c34-9708-19d1121514c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting all relevant docs from vector db\n",
    "retrieved_docs = retriever.get_relevant_documents(user_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b978ac06-b1ee-46e2-99ed-6394b38550b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0a659ad9-fa55-490b-a593-9b7cfc49becd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the unique urls\n",
    "unique_urls = set([doc.metadata['source'] for doc in retrieved_docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f55668d1-538b-486f-8a99-82873ed5cf6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'https://dune.com/docs/api/api-reference/',\n",
       " 'https://dune.com/docs/api/api-reference/edit-queries/',\n",
       " 'https://dune.com/docs/api/api-reference/edit-queries/archive-query/'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3d89a69e-c247-4699-9d94-7a2959bc0d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making list for needed to update\n",
    "document_list = load_document_as_array()\n",
    "# check every json, include it\n",
    "to_be_updated_docs = []\n",
    "for doc in document_list:\n",
    "    if doc[\"url\"] in unique_urls:\n",
    "        to_be_updated_docs.append(doc)\n",
    "\n",
    "# to_be_updated_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4bd0721b-17c7-4af9-9823-e00504e81c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to_be_updated_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e6b4fc45-2c24-4739-82f3-c5618d9a0c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to revise and restructure user query for communicating with language model\n",
    "from langchain.prompts import ChatPromptTemplate, PromptTemplate\n",
    "\n",
    "# prompt\n",
    "user_query_revise_prompt_template = \"\"\"User writes a query instruction to update his original document. Our system updates that original documents \n",
    "based on that query. You are a smart query modifiying assistant. Your task is to rephrase and restructure the given query so that it become a better \n",
    "prompt for communicating with a language model. If you can't, just say that you can't do. Keep the answer concise.\n",
    "Query: {question}\n",
    "\"\"\"\n",
    "user_query_revise_prompt = ChatPromptTemplate.from_template(user_query_revise_prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "832419f8-64f6-4088-ab65-0adc35f8b66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpt4 llm\n",
    "llm_gpt4 = ChatOpenAI(model_name=\"gpt-4-1106-preview\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "083bbf85-c4fd-49ec-aa43-70e4dc49d19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_gpt3 = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a5008c82-c2c9-4ddc-9150-cdf9284e44da",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = user_query_revise_prompt | llm_gpt3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ddfe56fc-03ed-4b04-b486-c5762a718857",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain.invoke({\"context\":\"\",\"question\":user_query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e720b368-ee93-4c53-8eb5-3cc2175ed7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_updated_query = response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3fc14f2c-85ff-4cfa-8c05-6720da888420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Please update all relevant information to reflect the change from archiving queries to deleting them entirely.'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_updated_query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1e12f8-8a2e-48e4-8703-c819888cc8e2",
   "metadata": {},
   "source": [
    "### Update documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c524ea99-5625-4004-b033-7563f1318be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "def num_tokens_from_string(string: str, encoding_name: str = \"cl100k_base\") -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens + 5 # 5 is the max additional tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "888cc936-462d-41e1-a4ef-d999f3f9d493",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_str(docs: list):\n",
    "    docs = [f\"[{doc}]\" for doc in docs]\n",
    "    return \"\".join(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "a66f33ae-6549-4997-9dc5-f59af3541645",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "# parse model\n",
    "class Document(BaseModel):\n",
    "    url: str = Field(description=\"url\")\n",
    "    content: str = Field(description=\"content\")\n",
    "\n",
    "# parse model\n",
    "class DocumentList(BaseModel):\n",
    "    docs: list = List[Document]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "40c51b2c-9073-4a8a-b6a9-4cb2f37a96a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use when total token more than 20k, then break it multiple times\n",
    "def get_llm_response(attached_doc_dict: str):\n",
    "    # prompt\n",
    "    doc_update_prompt_template = \"\"\"Update the given document list based on given query. Update one by one.\n",
    "    {format_instructions}\n",
    "    Query: {query}\n",
    "    Document list:\n",
    "    {context}\n",
    "    \"\"\"\n",
    "    parser = JsonOutputParser(pydantic_object=DocumentList)\n",
    "    doc_update_prompt = PromptTemplate(template=doc_update_prompt_template,\n",
    "                                               input_variables=[\"query\", \"context\"],\n",
    "                                               partial_variables={\"format_instructions\": parser.get_format_instructions()})\n",
    "    \n",
    "    chain = doc_update_prompt | llm_gpt3 | parser\n",
    "    \n",
    "    context_str = convert_to_str(list(attached_doc_dict.values()))\n",
    "    \n",
    "    response = chain.invoke({\"context\":context_str,\"query\":user_updated_query})\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8e65e313-94f9-4c4e-b685-e48dfb441548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse model\n",
    "class Document(BaseModel):\n",
    "    url: str = Field(description=\"url\")\n",
    "    content: str = Field(description=\"content\")\n",
    "\n",
    "parser = JsonOutputParser(pydantic_object=Document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73711c08-2152-4deb-9751-9ef1adc3f89f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "9ec6b645-1046-4124-beb9-46fd7133ba40",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_retrieved_docs = len(to_be_updated_docs)\n",
    "\n",
    "# final resultset\n",
    "results = {}\n",
    "\n",
    "if num_retrieved_docs > 25:\n",
    "    # take as batch and send to API\n",
    "    index = 0\n",
    "    updated_dict = []\n",
    "    attached_doc_dict = {}\n",
    "    while index < retrieve_doc_count:\n",
    "        list_str = \"\".join([str(dict_) for dict_ in list(attached_doc_dict.values())])\n",
    "\n",
    "        # \n",
    "        if num_tokens_from_string(list_str) < 1000:\n",
    "    \n",
    "            # add to dict\n",
    "            attached_doc_dict[to_be_updated_docs[index][\"url\"]] = to_be_updated_docs[index]\n",
    "            index += 1\n",
    "            \n",
    "        else:\n",
    "            # docs update here\n",
    "            \n",
    "            res_content = get_llm_response(attached_doc_dict)\n",
    "            # add updated doc to dict\n",
    "            updated_dict.append(response)\n",
    "            \n",
    "            # clear all data\n",
    "            attached_doc_dict = {}\n",
    "    \n",
    "    # now the rest one\n",
    "    res_content = get_llm_response(attached_doc_dict)\n",
    "    updated_dict.append(res_content)\n",
    "    \n",
    "else: # total number of retrieved document is less than 25\n",
    "    # to openAI one by one\n",
    "    # go through all of them seperately\n",
    "    for doc in to_be_updated_docs:\n",
    "        doc_update_prompt_template = \"\"\"Update the given document based on the given query.\n",
    "        {format_instructions}\n",
    "        Query:{query}\n",
    "        Document:{doc}\n",
    "        \"\"\"\n",
    "\n",
    "        parser = JsonOutputParser(pydantic_object=Document)\n",
    "        \n",
    "        doc_update_prompt = PromptTemplate(template=doc_update_prompt_template,\n",
    "                                               input_variables=[\"query\", \"doc\"],\n",
    "                                               partial_variables={\"format_instructions\": parser.get_format_instructions()})\n",
    "        \n",
    "        chain = doc_update_prompt | llm_gpt3 | parser\n",
    "        \n",
    "        response = chain.invoke({\"doc\":doc,\"query\":user_updated_query})\n",
    "        # save updated document against url to keep track\n",
    "        results[doc[\"url\"]] = response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7bb3bc-9fa5-4777-9d13-1a94cfe98da4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7aa27d61-9116-414a-9046-401ccddae193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "cfe9e334-9ab0-4a69-8319-0e4613ca04e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieve_doc_count = len(to_be_updated_docs)\n",
    "\n",
    "attached_doc_dict = {}\n",
    "updated_dict = []\n",
    "index = 0\n",
    "while index < retrieve_doc_count:\n",
    "    list_str = \"\".join([str(dict_) for dict_ in list(attached_doc_dict.values())])\n",
    "    \n",
    "    if num_tokens_from_string(list_str) < 1000:\n",
    "\n",
    "        # add to dict\n",
    "        attached_doc_dict[to_be_updated_docs[index][\"url\"]] = to_be_updated_docs[index]\n",
    "        index += 1\n",
    "        \n",
    "    else:\n",
    "        # docs update here\n",
    "        \n",
    "        res_content = get_llm_response(attached_doc_dict)\n",
    "        # add updated doc to dict\n",
    "        updated_dict.append(response.content)\n",
    "        \n",
    "        # clear all data\n",
    "        attached_doc_dict = {}\n",
    "\n",
    "# now the rest one\n",
    "res_content = get_llm_response(attached_doc_dict)\n",
    "updated_dict.append(res_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2a5dcd70-cfe9-4c86-89a4-d9f727783919",
   "metadata": {},
   "outputs": [],
   "source": [
    "#updated_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "989491b4-4607-4465-96c0-9e9500eedea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#attached_doc_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e86513-defd-434c-9bff-c28e7ce90bba",
   "metadata": {},
   "source": [
    "### Update main document and write two file: one contains error diff and other contains new updated json array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "377ad274-80e3-4a72-bf6f-c8802b0fa67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_document = load_document_as_array()\n",
    "\n",
    "doc_diffs = []\n",
    "\n",
    "# iterate all entity of documents and check\n",
    "for index in range(len(original_document)):\n",
    "    url = original_document[index][\"url\"]\n",
    "    if url in results.keys():\n",
    "        # add from original\n",
    "        doc_diffs.append(original_document[index][\"content\"])\n",
    "        # add from updated one\n",
    "        doc_diffs.append(results[url][\"content\"])\n",
    "        # update original document entity by updated one\n",
    "        original_document[index] = results[url]\n",
    "\n",
    "# doc_diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8f28861e-3080-4a5e-8609-a916cb2a0178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to a file :: updated json to new jsonl file\n",
    "def write_to_jsonl(documents: list, file_name: str):\n",
    "    with open(file_name, 'w') as file:\n",
    "        for json_obj in documents:\n",
    "            json_str = json.dumps(json_obj)\n",
    "            file.write(json_str + '\\n')\n",
    "    print(f\"Write to {file_name} done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "21127160-eb54-4a25-a593-f373b241d656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write to 2024-04-05_updated_document.jsonl done!\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "# current date\n",
    "today_ = datetime.today().date()\n",
    "file_name = f\"{str(today_)}_updated_document.jsonl\"\n",
    "write_to_jsonl(original_document, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b89ad3f5-38c8-44b2-a0b3-69e89b31219e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print all diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0ec583d2-5f6e-49b3-9da8-da14c37585f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc_diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "3bf3ccbc-767e-4c9e-b185-f3ffca752fe3",
   "metadata": {},
   "outputs": [
    {
     "ename": "VersionConflict",
     "evalue": "Package pydantic is installed but has a version conflict:\n    Requirement: pydantic<3,>=2\n    Installed: 1.10.4\nThis package is required for trulens_eval. Please resolve the conflict by\ninstalling a compatible version with:\n\n    ```bash\n    pip install 'pydantic<3,>=2'\n    ```\n\nIf you are running trulens_eval in a notebook, you may need to restart the\nkernel after resolving the conflict. If your distribution is in a bad place\nbeyond this package, you may need to reinstall trulens_eval so that all of the\ndependencies get installed and hopefully corrected:\n    \n    ```bash\n    pip uninstall -y trulens_eval\n    pip install trulens_eval\n    ```\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mVersionConflict\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[120], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtrulens_eval\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/trulens_eval/__init__.py:98\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;66;03m# This check is intentionally done ahead of the other imports as we want to\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;66;03m# print out a nice warning/error before an import error happens further down\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;66;03m# this sequence.\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtrulens_eval\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimports\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_imports\n\u001b[0;32m---> 98\u001b[0m check_imports()\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtrulens_eval\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeedback\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeedback\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Feedback\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtrulens_eval\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeedback\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprovider\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Provider\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/trulens_eval/utils/imports.py:220\u001b[0m, in \u001b[0;36mcheck_imports\u001b[0;34m(ignore_version_mismatch)\u001b[0m\n\u001b[1;32m    217\u001b[0m message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m MESSAGE_FRAGMENT_VERSION_MISMATCH_PIP\u001b[38;5;241m.\u001b[39mformat(req\u001b[38;5;241m=\u001b[39mreq)\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m is_optional) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m ignore_version_mismatch):\n\u001b[0;32m--> 220\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m VersionConflict(message)\n\u001b[1;32m    222\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(message)\n",
      "\u001b[0;31mVersionConflict\u001b[0m: Package pydantic is installed but has a version conflict:\n    Requirement: pydantic<3,>=2\n    Installed: 1.10.4\nThis package is required for trulens_eval. Please resolve the conflict by\ninstalling a compatible version with:\n\n    ```bash\n    pip install 'pydantic<3,>=2'\n    ```\n\nIf you are running trulens_eval in a notebook, you may need to restart the\nkernel after resolving the conflict. If your distribution is in a bad place\nbeyond this package, you may need to reinstall trulens_eval so that all of the\ndependencies get installed and hopefully corrected:\n    \n    ```bash\n    pip uninstall -y trulens_eval\n    pip install trulens_eval\n    ```\n"
     ]
    }
   ],
   "source": [
    "import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6b8c6f-7c52-4017-a1d7-705fb3c9b257",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
