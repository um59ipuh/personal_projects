{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6faaa552-0a75-4242-b240-015e77930a6a",
   "metadata": {},
   "source": [
    "## Process :: Loading docs & credentials -> Indexing -> retrieval -> updating"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f1f0de-6493-49d6-8040-2d201e37bb7b",
   "metadata": {},
   "source": [
    "### Imstalling and importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51eec853-13e2-40af-b0e3-fa904361334b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "39bb2b2c-f401-494b-a7a3-8370972e64bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain_community in /opt/anaconda3/lib/python3.11/site-packages (0.0.31)\n",
      "Requirement already satisfied: tiktoken in /opt/anaconda3/lib/python3.11/site-packages (0.6.0)\n",
      "Requirement already satisfied: langchain-openai in /opt/anaconda3/lib/python3.11/site-packages (0.1.1)\n",
      "Requirement already satisfied: langchainhub in /opt/anaconda3/lib/python3.11/site-packages (0.1.15)\n",
      "Requirement already satisfied: chromadb in /opt/anaconda3/lib/python3.11/site-packages (0.4.24)\n",
      "Requirement already satisfied: langchain in /opt/anaconda3/lib/python3.11/site-packages (0.1.14)\n",
      "Requirement already satisfied: openai in /opt/anaconda3/lib/python3.11/site-packages (1.16.1)\n",
      "Requirement already satisfied: jq in /opt/anaconda3/lib/python3.11/site-packages (1.7.0)\n",
      "Requirement already satisfied: trulens-eval in /opt/anaconda3/lib/python3.11/site-packages (0.27.2)\n",
      "Requirement already satisfied: pydantic in /opt/anaconda3/lib/python3.11/site-packages (2.6.4)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/anaconda3/lib/python3.11/site-packages (from langchain_community) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/anaconda3/lib/python3.11/site-packages (from langchain_community) (2.0.25)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/anaconda3/lib/python3.11/site-packages (from langchain_community) (3.9.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/anaconda3/lib/python3.11/site-packages (from langchain_community) (0.6.4)\n",
      "Requirement already satisfied: langchain-core<0.2.0,>=0.1.37 in /opt/anaconda3/lib/python3.11/site-packages (from langchain_community) (0.1.39)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /opt/anaconda3/lib/python3.11/site-packages (from langchain_community) (0.1.39)\n",
      "Requirement already satisfied: numpy<2,>=1 in /opt/anaconda3/lib/python3.11/site-packages (from langchain_community) (1.26.4)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/anaconda3/lib/python3.11/site-packages (from langchain_community) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /opt/anaconda3/lib/python3.11/site-packages (from langchain_community) (8.2.3)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/anaconda3/lib/python3.11/site-packages (from tiktoken) (2023.10.3)\n",
      "Requirement already satisfied: types-requests<3.0.0.0,>=2.31.0.2 in /opt/anaconda3/lib/python3.11/site-packages (from langchainhub) (2.31.0.20240403)\n",
      "Requirement already satisfied: build>=1.0.3 in /opt/anaconda3/lib/python3.11/site-packages (from chromadb) (1.2.1)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.3 in /opt/anaconda3/lib/python3.11/site-packages (from chromadb) (0.7.3)\n",
      "Requirement already satisfied: fastapi>=0.95.2 in /opt/anaconda3/lib/python3.11/site-packages (from chromadb) (0.110.1)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in /opt/anaconda3/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.29.0)\n",
      "Requirement already satisfied: posthog>=2.4.0 in /opt/anaconda3/lib/python3.11/site-packages (from chromadb) (3.5.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /opt/anaconda3/lib/python3.11/site-packages (from chromadb) (4.9.0)\n",
      "Requirement already satisfied: pulsar-client>=3.1.0 in /opt/anaconda3/lib/python3.11/site-packages (from chromadb) (3.4.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in /opt/anaconda3/lib/python3.11/site-packages (from chromadb) (1.16.3)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in /opt/anaconda3/lib/python3.11/site-packages (from chromadb) (1.24.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /opt/anaconda3/lib/python3.11/site-packages (from chromadb) (1.24.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /opt/anaconda3/lib/python3.11/site-packages (from chromadb) (0.45b0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /opt/anaconda3/lib/python3.11/site-packages (from chromadb) (1.24.0)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /opt/anaconda3/lib/python3.11/site-packages (from chromadb) (0.15.2)\n",
      "Requirement already satisfied: pypika>=0.48.9 in /opt/anaconda3/lib/python3.11/site-packages (from chromadb) (0.48.9)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in /opt/anaconda3/lib/python3.11/site-packages (from chromadb) (4.66.2)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /opt/anaconda3/lib/python3.11/site-packages (from chromadb) (7.4.0)\n",
      "Requirement already satisfied: importlib-resources in /opt/anaconda3/lib/python3.11/site-packages (from chromadb) (6.4.0)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /opt/anaconda3/lib/python3.11/site-packages (from chromadb) (1.62.1)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in /opt/anaconda3/lib/python3.11/site-packages (from chromadb) (4.1.2)\n",
      "Requirement already satisfied: typer>=0.9.0 in /opt/anaconda3/lib/python3.11/site-packages (from chromadb) (0.12.1)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in /opt/anaconda3/lib/python3.11/site-packages (from chromadb) (29.0.0)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in /opt/anaconda3/lib/python3.11/site-packages (from chromadb) (4.1.0)\n",
      "Requirement already satisfied: orjson>=3.9.12 in /opt/anaconda3/lib/python3.11/site-packages (from chromadb) (3.10.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/anaconda3/lib/python3.11/site-packages (from langchain) (1.33)\n",
      "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /opt/anaconda3/lib/python3.11/site-packages (from langchain) (0.0.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/anaconda3/lib/python3.11/site-packages (from openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/anaconda3/lib/python3.11/site-packages (from openai) (1.8.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/anaconda3/lib/python3.11/site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/lib/python3.11/site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: frozendict>=2.3.8 in /opt/anaconda3/lib/python3.11/site-packages (from trulens-eval) (2.4.1)\n",
      "Requirement already satisfied: munch>=3.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from trulens-eval) (4.0.0)\n",
      "Requirement already satisfied: dill>=0.3.7 in /opt/anaconda3/lib/python3.11/site-packages (from trulens-eval) (0.3.7)\n",
      "Requirement already satisfied: nltk>=3.8.1 in /opt/anaconda3/lib/python3.11/site-packages (from trulens-eval) (3.8.1)\n",
      "Requirement already satisfied: nest-asyncio>=1.5.8 in /opt/anaconda3/lib/python3.11/site-packages (from trulens-eval) (1.6.0)\n",
      "Requirement already satisfied: psutil>=5.9.8 in /opt/anaconda3/lib/python3.11/site-packages (from trulens-eval) (5.9.8)\n",
      "Requirement already satisfied: pip>=24.0 in /opt/anaconda3/lib/python3.11/site-packages (from trulens-eval) (24.0)\n",
      "Requirement already satisfied: packaging>=23.2 in /opt/anaconda3/lib/python3.11/site-packages (from trulens-eval) (23.2)\n",
      "Requirement already satisfied: python-dotenv>=1.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from trulens-eval) (1.0.1)\n",
      "Requirement already satisfied: merkle-json>=1.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from trulens-eval) (1.0.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /opt/anaconda3/lib/python3.11/site-packages (from trulens-eval) (0.9.0)\n",
      "Requirement already satisfied: millify>=0.1.1 in /opt/anaconda3/lib/python3.11/site-packages (from trulens-eval) (0.1.1)\n",
      "Requirement already satisfied: humanize>=4.6.0 in /opt/anaconda3/lib/python3.11/site-packages (from trulens-eval) (4.9.0)\n",
      "Requirement already satisfied: streamlit>=1.32.2 in /opt/anaconda3/lib/python3.11/site-packages (from trulens-eval) (1.33.0)\n",
      "Requirement already satisfied: streamlit-aggrid==0.3.4 in /opt/anaconda3/lib/python3.11/site-packages (from trulens-eval) (0.3.4)\n",
      "Requirement already satisfied: streamlit-extras>=0.4.0 in /opt/anaconda3/lib/python3.11/site-packages (from trulens-eval) (0.4.2)\n",
      "Requirement already satisfied: rich>=13.6.0 in /opt/anaconda3/lib/python3.11/site-packages (from trulens-eval) (13.7.1)\n",
      "Requirement already satisfied: alembic>=1.11.2 in /opt/anaconda3/lib/python3.11/site-packages (from trulens-eval) (1.13.1)\n",
      "Requirement already satisfied: pandas>=1.2 in /opt/anaconda3/lib/python3.11/site-packages (from streamlit-aggrid==0.3.4->trulens-eval) (2.1.4)\n",
      "Requirement already satisfied: python-decouple<4.0,>=3.6 in /opt/anaconda3/lib/python3.11/site-packages (from streamlit-aggrid==0.3.4->trulens-eval) (3.8)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/anaconda3/lib/python3.11/site-packages (from pydantic) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in /opt/anaconda3/lib/python3.11/site-packages (from pydantic) (2.16.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.9.3)\n",
      "Requirement already satisfied: Mako in /opt/anaconda3/lib/python3.11/site-packages (from alembic>=1.11.2->trulens-eval) (1.3.2)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/anaconda3/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: pyproject_hooks in /opt/anaconda3/lib/python3.11/site-packages (from build>=1.0.3->chromadb) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/anaconda3/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.21.1)\n",
      "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in /opt/anaconda3/lib/python3.11/site-packages (from fastapi>=0.95.2->chromadb) (0.37.2)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/anaconda3/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/anaconda3/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.1)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/anaconda3/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /opt/anaconda3/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /opt/anaconda3/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (2.29.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /opt/anaconda3/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (0.58.0)\n",
      "Requirement already satisfied: requests-oauthlib in /opt/anaconda3/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /opt/anaconda3/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in /opt/anaconda3/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (2.0.7)\n",
      "Requirement already satisfied: click in /opt/anaconda3/lib/python3.11/site-packages (from nltk>=3.8.1->trulens-eval) (8.1.7)\n",
      "Requirement already satisfied: joblib in /opt/anaconda3/lib/python3.11/site-packages (from nltk>=3.8.1->trulens-eval) (1.2.0)\n",
      "Requirement already satisfied: coloredlogs in /opt/anaconda3/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /opt/anaconda3/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb) (24.3.25)\n",
      "Requirement already satisfied: protobuf in /opt/anaconda3/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb) (3.20.3)\n",
      "Requirement already satisfied: sympy in /opt/anaconda3/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb) (1.12)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /opt/anaconda3/lib/python3.11/site-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.14)\n",
      "Requirement already satisfied: importlib-metadata<=7.0,>=6.0 in /opt/anaconda3/lib/python3.11/site-packages (from opentelemetry-api>=1.2.0->chromadb) (7.0.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /opt/anaconda3/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.63.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.24.0 in /opt/anaconda3/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.24.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.24.0 in /opt/anaconda3/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.24.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.45b0 in /opt/anaconda3/lib/python3.11/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.45b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.45b0 in /opt/anaconda3/lib/python3.11/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.45b0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.45b0 in /opt/anaconda3/lib/python3.11/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.45b0)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.45b0 in /opt/anaconda3/lib/python3.11/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.45b0)\n",
      "Requirement already satisfied: setuptools>=16.0 in /opt/anaconda3/lib/python3.11/site-packages (from opentelemetry-instrumentation==0.45b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (68.2.2)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from opentelemetry-instrumentation==0.45b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.14.1)\n",
      "Requirement already satisfied: asgiref~=3.0 in /opt/anaconda3/lib/python3.11/site-packages (from opentelemetry-instrumentation-asgi==0.45b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.8.1)\n",
      "Requirement already satisfied: monotonic>=1.5 in /opt/anaconda3/lib/python3.11/site-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /opt/anaconda3/lib/python3.11/site-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3,>=2->langchain_community) (2.0.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/anaconda3/lib/python3.11/site-packages (from rich>=13.6.0->trulens-eval) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/lib/python3.11/site-packages (from rich>=13.6.0->trulens-eval) (2.15.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/anaconda3/lib/python3.11/site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.0.1)\n",
      "Requirement already satisfied: altair<6,>=4.0 in /opt/anaconda3/lib/python3.11/site-packages (from streamlit>=1.32.2->trulens-eval) (5.0.1)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from streamlit>=1.32.2->trulens-eval) (1.6.2)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in /opt/anaconda3/lib/python3.11/site-packages (from streamlit>=1.32.2->trulens-eval) (4.2.2)\n",
      "Requirement already satisfied: pillow<11,>=7.1.0 in /opt/anaconda3/lib/python3.11/site-packages (from streamlit>=1.32.2->trulens-eval) (10.2.0)\n",
      "Requirement already satisfied: pyarrow>=7.0 in /opt/anaconda3/lib/python3.11/site-packages (from streamlit>=1.32.2->trulens-eval) (14.0.2)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in /opt/anaconda3/lib/python3.11/site-packages (from streamlit>=1.32.2->trulens-eval) (0.10.2)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /opt/anaconda3/lib/python3.11/site-packages (from streamlit>=1.32.2->trulens-eval) (3.1.37)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /opt/anaconda3/lib/python3.11/site-packages (from streamlit>=1.32.2->trulens-eval) (0.8.0)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in /opt/anaconda3/lib/python3.11/site-packages (from streamlit>=1.32.2->trulens-eval) (6.3.3)\n",
      "Requirement already satisfied: entrypoints>=0.4 in /opt/anaconda3/lib/python3.11/site-packages (from streamlit-extras>=0.4.0->trulens-eval) (0.4)\n",
      "Requirement already satisfied: htbuilder>=0.6.2 in /opt/anaconda3/lib/python3.11/site-packages (from streamlit-extras>=0.4.0->trulens-eval) (0.6.2)\n",
      "Requirement already satisfied: markdownlit>=0.0.5 in /opt/anaconda3/lib/python3.11/site-packages (from streamlit-extras>=0.4.0->trulens-eval) (0.0.7)\n",
      "Requirement already satisfied: prometheus-client>=0.14.0 in /opt/anaconda3/lib/python3.11/site-packages (from streamlit-extras>=0.4.0->trulens-eval) (0.14.1)\n",
      "Requirement already satisfied: st-annotated-text>=3.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from streamlit-extras>=0.4.0->trulens-eval) (4.0.1)\n",
      "Requirement already satisfied: streamlit-camera-input-live>=0.2.0 in /opt/anaconda3/lib/python3.11/site-packages (from streamlit-extras>=0.4.0->trulens-eval) (0.2.0)\n",
      "Requirement already satisfied: streamlit-card>=0.0.4 in /opt/anaconda3/lib/python3.11/site-packages (from streamlit-extras>=0.4.0->trulens-eval) (1.0.0)\n",
      "Requirement already satisfied: streamlit-embedcode>=0.1.2 in /opt/anaconda3/lib/python3.11/site-packages (from streamlit-extras>=0.4.0->trulens-eval) (0.1.2)\n",
      "Requirement already satisfied: streamlit-faker>=0.0.2 in /opt/anaconda3/lib/python3.11/site-packages (from streamlit-extras>=0.4.0->trulens-eval) (0.0.3)\n",
      "Requirement already satisfied: streamlit-image-coordinates<0.2.0,>=0.1.1 in /opt/anaconda3/lib/python3.11/site-packages (from streamlit-extras>=0.4.0->trulens-eval) (0.1.6)\n",
      "Requirement already satisfied: streamlit-keyup>=0.1.9 in /opt/anaconda3/lib/python3.11/site-packages (from streamlit-extras>=0.4.0->trulens-eval) (0.2.4)\n",
      "Requirement already satisfied: streamlit-toggle-switch>=1.0.2 in /opt/anaconda3/lib/python3.11/site-packages (from streamlit-extras>=0.4.0->trulens-eval) (1.0.2)\n",
      "Requirement already satisfied: streamlit-vertical-slider>=2.5.5 in /opt/anaconda3/lib/python3.11/site-packages (from streamlit-extras>=0.4.0->trulens-eval) (2.5.5)\n",
      "Requirement already satisfied: validators>=0.20.0 in /opt/anaconda3/lib/python3.11/site-packages (from streamlit-extras>=0.4.0->trulens-eval) (0.28.0)\n",
      "Requirement already satisfied: huggingface_hub<1.0,>=0.16.4 in /opt/anaconda3/lib/python3.11/site-packages (from tokenizers>=0.13.2->chromadb) (0.22.2)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /opt/anaconda3/lib/python3.11/site-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/anaconda3/lib/python3.11/site-packages (from typing-inspect>=0.8.0->trulens-eval) (1.0.0)\n",
      "Requirement already satisfied: httptools>=0.5.0 in /opt/anaconda3/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.1)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /opt/anaconda3/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.19.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /opt/anaconda3/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
      "Requirement already satisfied: websockets>=10.4 in /opt/anaconda3/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (12.0)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.11/site-packages (from altair<6,>=4.0->streamlit>=1.32.2->trulens-eval) (3.1.3)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /opt/anaconda3/lib/python3.11/site-packages (from altair<6,>=4.0->streamlit>=1.32.2->trulens-eval) (4.19.2)\n",
      "Requirement already satisfied: toolz in /opt/anaconda3/lib/python3.11/site-packages (from altair<6,>=4.0->streamlit>=1.32.2->trulens-eval) (0.12.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/anaconda3/lib/python3.11/site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit>=1.32.2->trulens-eval) (4.0.7)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/anaconda3/lib/python3.11/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/anaconda3/lib/python3.11/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
      "Requirement already satisfied: more-itertools in /opt/anaconda3/lib/python3.11/site-packages (from htbuilder>=0.6.2->streamlit-extras>=0.4.0->trulens-eval) (10.1.0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.11/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/lib/python3.11/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2023.10.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/anaconda3/lib/python3.11/site-packages (from importlib-metadata<=7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.17.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=13.6.0->trulens-eval) (0.1.0)\n",
      "Requirement already satisfied: markdown in /opt/anaconda3/lib/python3.11/site-packages (from markdownlit>=0.0.5->streamlit-extras>=0.4.0->trulens-eval) (3.6)\n",
      "Requirement already satisfied: lxml in /opt/anaconda3/lib/python3.11/site-packages (from markdownlit>=0.0.5->streamlit-extras>=0.4.0->trulens-eval) (4.9.3)\n",
      "Requirement already satisfied: favicon in /opt/anaconda3/lib/python3.11/site-packages (from markdownlit>=0.0.5->streamlit-extras>=0.4.0->trulens-eval) (0.7.0)\n",
      "Requirement already satisfied: pymdown-extensions in /opt/anaconda3/lib/python3.11/site-packages (from markdownlit>=0.0.5->streamlit-extras>=0.4.0->trulens-eval) (10.7.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.11/site-packages (from pandas>=1.2->streamlit-aggrid==0.3.4->trulens-eval) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/anaconda3/lib/python3.11/site-packages (from pandas>=1.2->streamlit-aggrid==0.3.4->trulens-eval) (2023.3)\n",
      "Requirement already satisfied: faker in /opt/anaconda3/lib/python3.11/site-packages (from streamlit-faker>=0.0.2->streamlit-extras>=0.4.0->trulens-eval) (24.4.0)\n",
      "Requirement already satisfied: matplotlib in /opt/anaconda3/lib/python3.11/site-packages (from streamlit-faker>=0.0.2->streamlit-extras>=0.4.0->trulens-eval) (3.8.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /opt/anaconda3/lib/python3.11/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /opt/anaconda3/lib/python3.11/site-packages (from Mako->alembic>=1.11.2->trulens-eval) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/anaconda3/lib/python3.11/site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Requirement already satisfied: smmap<5,>=3.0.1 in /opt/anaconda3/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit>=1.32.2->trulens-eval) (4.0.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/anaconda3/lib/python3.11/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=1.32.2->trulens-eval) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/anaconda3/lib/python3.11/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=1.32.2->trulens-eval) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/anaconda3/lib/python3.11/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=1.32.2->trulens-eval) (0.10.6)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/anaconda3/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.8)\n",
      "Requirement already satisfied: beautifulsoup4>=4.7.0 in /opt/anaconda3/lib/python3.11/site-packages (from favicon->markdownlit>=0.0.5->streamlit-extras>=0.4.0->trulens-eval) (4.12.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/lib/python3.11/site-packages (from matplotlib->streamlit-faker>=0.0.2->streamlit-extras>=0.4.0->trulens-eval) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/lib/python3.11/site-packages (from matplotlib->streamlit-faker>=0.0.2->streamlit-extras>=0.4.0->trulens-eval) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/lib/python3.11/site-packages (from matplotlib->streamlit-faker>=0.0.2->streamlit-extras>=0.4.0->trulens-eval) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/anaconda3/lib/python3.11/site-packages (from matplotlib->streamlit-faker>=0.0.2->streamlit-extras>=0.4.0->trulens-eval) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/lib/python3.11/site-packages (from matplotlib->streamlit-faker>=0.0.2->streamlit-extras>=0.4.0->trulens-eval) (3.0.9)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/anaconda3/lib/python3.11/site-packages (from beautifulsoup4>=4.7.0->favicon->markdownlit>=0.0.5->streamlit-extras>=0.4.0->trulens-eval) (2.5)\n"
     ]
    }
   ],
   "source": [
    "! pip install langchain_community tiktoken langchain-openai langchainhub chromadb langchain openai jq trulens-eval pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fea133-037b-426c-8dad-1cf1d4c8f93e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3e55f4e-18e5-44ac-b47e-d04e8df4bbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing\n",
    "from langchain import hub\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26256a8a-86e7-45e8-8919-3d30bd1a02cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "be358bf8-981a-49b4-ac33-b28797935ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# credential loading and set to environment\n",
    "import json\n",
    "def get_credentials(file_path:str=\"credentials.json\"):\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "import os\n",
    "openai_api_key = get_credentials()['openai_api_Key_aweqa']\n",
    "# set key to environment\n",
    "os.environ['OPENAI_API_KEY'] = openai_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e3354c6-215f-465c-b50b-437b8428a2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819f0a20-bf14-4c68-8ab6-1e606f59bba5",
   "metadata": {},
   "source": [
    "### load document -> splitting -> indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "069c16a8-0dd2-4369-88bc-196d67a857b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2580"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "def load_document_as_array(file_path:str = \"./data/scraped_data.jsonl\"):\n",
    "    data = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            json_object = json.loads(line)\n",
    "            data.append(json_object)\n",
    "    return data\n",
    "\n",
    "len(load_document_as_array())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d3abd97-19e9-4635-a821-ef4982dc0eda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': \"Skip to content\\n          (#start-building) \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n  (https://github.com/duneanalytics/docs/edit/master/docs/index.md) \\n Welcome \\n Dune is a web-based platform that allows you to query public blockchain data and aggregate it into beautiful dashboards. \\n \\n Quickstart \\n To get started with Dune in 5 minutes, see the  Quickstart  (quickstart/) . \\n \\n \\n \\n The world's blockchain data at your fingertips! \\n \\n Blockchains are open and transparent, but each chain is unique—making it difficult to understand, ingest, and aggregate data. Dune gives you the proper tools to analyze cross-chain data for different tokens, wallets, and protocols. You can also easily share your work with the community. \\n \",\n",
       " 'url': 'https://dune.com/docs/'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(load_document_as_array()[0])\n",
    "load_document_as_array()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "702c6071-1542-463e-9860-51d3eec27692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking is there already exists or not\n",
    "persist_directory = 'vector_db'\n",
    "# embedding \n",
    "embedding = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd264ed-2291-4ac2-b7d4-cf0a253d2130",
   "metadata": {},
   "source": [
    "### load document for splitting and split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a63dd3a8-c421-4325-a210-fae91c4cd348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# meta data function :: add source url as metadata instead of disk path\n",
    "def metadata_func(record: dict, metadata: dict) -> dict:\n",
    "    if \"source\" in metadata:\n",
    "        metadata[\"source\"] = record.get(\"url\")\n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e36fb399-6594-466e-9398-44585cb032f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import JSONLoader for JSON Line loading\n",
    "from langchain_community.document_loaders import JSONLoader\n",
    "\n",
    "loader = JSONLoader(\n",
    "    file_path='./data/scraped_data.jsonl',\n",
    "    jq_schema='.',\n",
    "    text_content=False,\n",
    "    json_lines=True,\n",
    "    metadata_func=metadata_func)\n",
    "\n",
    "document = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "15c72e18-d9f8-491c-a6bb-e3e345502b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=300, \n",
    "    chunk_overlap=50)\n",
    "\n",
    "# Make splits\n",
    "splits = text_splitter.split_documents(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "662f9f68-fb5f-41ef-8a53-ae682479de21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "78a8010d-044d-4014-adeb-d724fba5e204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# indexing and persist\n",
    "persist_directory = 'vector_db'\n",
    "vectorstore = Chroma.from_documents(documents=splits, \n",
    "                                    embedding=OpenAIEmbeddings(),\n",
    "                                    persist_directory=persist_directory)\n",
    "\n",
    "# retriever of vector db\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61eec273-4f1d-4664-8e65-f413a37f8ce7",
   "metadata": {},
   "source": [
    "### Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a7f1a6-d49c-43fa-842b-cf8446c61cd6",
   "metadata": {},
   "source": [
    "#### User input here : change query in user_query variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c6f71028-beb5-4c91-969b-7b921d64b2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the user query here:: edit the user_query variable from here.\n",
    "user_query = \"\"\"We removed the ability to archive queries, and instead added the ability to completely delete them. \n",
    "Update all relevant knowledge\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a2ed37ff-ba72-4c34-9708-19d1121514c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting all relevant docs from vector db\n",
    "retrieved_docs = retriever.get_relevant_documents(user_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b978ac06-b1ee-46e2-99ed-6394b38550b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0a659ad9-fa55-490b-a593-9b7cfc49becd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the unique urls\n",
    "unique_urls = set([doc.metadata['source'] for doc in retrieved_docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f55668d1-538b-486f-8a99-82873ed5cf6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'https://dune.com/docs/api/api-reference/',\n",
       " 'https://dune.com/docs/api/api-reference/edit-queries/',\n",
       " 'https://dune.com/docs/api/api-reference/edit-queries/archive-query/'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3d89a69e-c247-4699-9d94-7a2959bc0d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making list for needed to update\n",
    "document_list = load_document_as_array()\n",
    "# check every json, include it\n",
    "to_be_updated_docs = []\n",
    "for doc in document_list:\n",
    "    if doc[\"url\"] in unique_urls:\n",
    "        to_be_updated_docs.append(doc)\n",
    "\n",
    "# to_be_updated_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4bd0721b-17c7-4af9-9823-e00504e81c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to_be_updated_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e6b4fc45-2c24-4739-82f3-c5618d9a0c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to revise and restructure user query for communicating with language model\n",
    "from langchain.prompts import ChatPromptTemplate, PromptTemplate\n",
    "\n",
    "# prompt\n",
    "user_query_revise_prompt_template = \"\"\"User writes a query instruction to update his original document. Our system updates that original documents \n",
    "based on that query. You are a smart query modifiying assistant. Your task is to rephrase and restructure the given query so that it become a better \n",
    "prompt for communicating with a language model. If you can't, just say that you can't do. Keep the answer concise.\n",
    "Query: {question}\n",
    "\"\"\"\n",
    "user_query_revise_prompt = ChatPromptTemplate.from_template(user_query_revise_prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "832419f8-64f6-4088-ab65-0adc35f8b66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpt4 llm\n",
    "llm_gpt4 = ChatOpenAI(model_name=\"gpt-4-1106-preview\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "083bbf85-c4fd-49ec-aa43-70e4dc49d19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_gpt3 = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a5008c82-c2c9-4ddc-9150-cdf9284e44da",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = user_query_revise_prompt | llm_gpt3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ddfe56fc-03ed-4b04-b486-c5762a718857",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain.invoke({\"context\":\"\",\"question\":user_query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e720b368-ee93-4c53-8eb5-3cc2175ed7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_updated_query = response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3fc14f2c-85ff-4cfa-8c05-6720da888420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Please update all relevant information to reflect the change from archiving queries to deleting them entirely.'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_updated_query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1e12f8-8a2e-48e4-8703-c819888cc8e2",
   "metadata": {},
   "source": [
    "### Update documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c524ea99-5625-4004-b033-7563f1318be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "def num_tokens_from_string(string: str, encoding_name: str = \"cl100k_base\") -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens + 5 # 5 is the max additional tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "888cc936-462d-41e1-a4ef-d999f3f9d493",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_str(docs: list):\n",
    "    docs = [f\"[{doc}]\" for doc in docs]\n",
    "    return \"\".join(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "a66f33ae-6549-4997-9dc5-f59af3541645",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "# parse model\n",
    "class Document(BaseModel):\n",
    "    url: str = Field(description=\"url\")\n",
    "    content: str = Field(description=\"content\")\n",
    "\n",
    "# parse model\n",
    "class DocumentList(BaseModel):\n",
    "    docs: list = List[Document]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "40c51b2c-9073-4a8a-b6a9-4cb2f37a96a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use when total token more than 20k, then break it multiple times\n",
    "def get_llm_response(attached_doc_dict: str):\n",
    "    # prompt\n",
    "    doc_update_prompt_template = \"\"\"Update the given document list based on given query. Update one by one.\n",
    "    {format_instructions}\n",
    "    Query: {query}\n",
    "    Document list:\n",
    "    {context}\n",
    "    \"\"\"\n",
    "    parser = JsonOutputParser(pydantic_object=DocumentList)\n",
    "    doc_update_prompt = PromptTemplate(template=doc_update_prompt_template,\n",
    "                                               input_variables=[\"query\", \"context\"],\n",
    "                                               partial_variables={\"format_instructions\": parser.get_format_instructions()})\n",
    "    \n",
    "    chain = doc_update_prompt | llm_gpt3 | parser\n",
    "    \n",
    "    context_str = convert_to_str(list(attached_doc_dict.values()))\n",
    "    \n",
    "    response = chain.invoke({\"context\":context_str,\"query\":user_updated_query})\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8e65e313-94f9-4c4e-b685-e48dfb441548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse model\n",
    "class Document(BaseModel):\n",
    "    url: str = Field(description=\"url\")\n",
    "    content: str = Field(description=\"content\")\n",
    "\n",
    "parser = JsonOutputParser(pydantic_object=Document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73711c08-2152-4deb-9751-9ef1adc3f89f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "9ec6b645-1046-4124-beb9-46fd7133ba40",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_retrieved_docs = len(to_be_updated_docs)\n",
    "\n",
    "# final resultset\n",
    "results = {}\n",
    "\n",
    "if num_retrieved_docs > 25:\n",
    "    # take as batch and send to API\n",
    "    index = 0\n",
    "    updated_dict = []\n",
    "    attached_doc_dict = {}\n",
    "    while index < retrieve_doc_count:\n",
    "        list_str = \"\".join([str(dict_) for dict_ in list(attached_doc_dict.values())])\n",
    "\n",
    "        # \n",
    "        if num_tokens_from_string(list_str) < 1000:\n",
    "    \n",
    "            # add to dict\n",
    "            attached_doc_dict[to_be_updated_docs[index][\"url\"]] = to_be_updated_docs[index]\n",
    "            index += 1\n",
    "            \n",
    "        else:\n",
    "            # docs update here\n",
    "            \n",
    "            res_content = get_llm_response(attached_doc_dict)\n",
    "            # add updated doc to dict\n",
    "            updated_dict.append(response)\n",
    "            \n",
    "            # clear all data\n",
    "            attached_doc_dict = {}\n",
    "    \n",
    "    # now the rest one\n",
    "    res_content = get_llm_response(attached_doc_dict)\n",
    "    updated_dict.append(res_content)\n",
    "    \n",
    "else: # total number of retrieved document is less than 25\n",
    "    # to openAI one by one\n",
    "    # go through all of them seperately\n",
    "    for doc in to_be_updated_docs:\n",
    "        doc_update_prompt_template = \"\"\"Update the given document based on the given query.\n",
    "        {format_instructions}\n",
    "        Query:{query}\n",
    "        Document:{doc}\n",
    "        \"\"\"\n",
    "\n",
    "        parser = JsonOutputParser(pydantic_object=Document)\n",
    "        \n",
    "        doc_update_prompt = PromptTemplate(template=doc_update_prompt_template,\n",
    "                                               input_variables=[\"query\", \"doc\"],\n",
    "                                               partial_variables={\"format_instructions\": parser.get_format_instructions()})\n",
    "        \n",
    "        chain = doc_update_prompt | llm_gpt3 | parser\n",
    "        \n",
    "        response = chain.invoke({\"doc\":doc,\"query\":user_updated_query})\n",
    "        # save updated document against url to keep track\n",
    "        results[doc[\"url\"]] = response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7bb3bc-9fa5-4777-9d13-1a94cfe98da4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7aa27d61-9116-414a-9046-401ccddae193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "cfe9e334-9ab0-4a69-8319-0e4613ca04e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieve_doc_count = len(to_be_updated_docs)\n",
    "\n",
    "attached_doc_dict = {}\n",
    "updated_dict = []\n",
    "index = 0\n",
    "while index < retrieve_doc_count:\n",
    "    list_str = \"\".join([str(dict_) for dict_ in list(attached_doc_dict.values())])\n",
    "    \n",
    "    if num_tokens_from_string(list_str) < 1000:\n",
    "\n",
    "        # add to dict\n",
    "        attached_doc_dict[to_be_updated_docs[index][\"url\"]] = to_be_updated_docs[index]\n",
    "        index += 1\n",
    "        \n",
    "    else:\n",
    "        # docs update here\n",
    "        \n",
    "        res_content = get_llm_response(attached_doc_dict)\n",
    "        # add updated doc to dict\n",
    "        updated_dict.append(response.content)\n",
    "        \n",
    "        # clear all data\n",
    "        attached_doc_dict = {}\n",
    "\n",
    "# now the rest one\n",
    "res_content = get_llm_response(attached_doc_dict)\n",
    "updated_dict.append(res_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2a5dcd70-cfe9-4c86-89a4-d9f727783919",
   "metadata": {},
   "outputs": [],
   "source": [
    "#updated_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "989491b4-4607-4465-96c0-9e9500eedea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#attached_doc_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e86513-defd-434c-9bff-c28e7ce90bba",
   "metadata": {},
   "source": [
    "### Update main document and write two file: one contains error diff and other contains new updated json array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "377ad274-80e3-4a72-bf6f-c8802b0fa67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_document = load_document_as_array()\n",
    "\n",
    "doc_diffs = []\n",
    "\n",
    "# iterate all entity of documents and check\n",
    "for index in range(len(original_document)):\n",
    "    url = original_document[index][\"url\"]\n",
    "    if url in results.keys():\n",
    "        # add from original\n",
    "        doc_diffs.append(original_document[index][\"content\"])\n",
    "        # add from updated one\n",
    "        doc_diffs.append(results[url][\"content\"])\n",
    "        # update original document entity by updated one\n",
    "        original_document[index] = results[url]\n",
    "\n",
    "# doc_diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8f28861e-3080-4a5e-8609-a916cb2a0178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to a file :: updated json to new jsonl file\n",
    "def write_to_jsonl(documents: list, file_name: str):\n",
    "    with open(file_name, 'w') as file:\n",
    "        for json_obj in documents:\n",
    "            json_str = json.dumps(json_obj)\n",
    "            file.write(json_str + '\\n')\n",
    "    print(f\"Write to {file_name} done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "21127160-eb54-4a25-a593-f373b241d656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write to 2024-04-05_updated_document.jsonl done!\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "# current date\n",
    "today_ = datetime.today().date()\n",
    "file_name = f\"{str(today_)}_updated_document.jsonl\"\n",
    "write_to_jsonl(original_document, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b89ad3f5-38c8-44b2-a0b3-69e89b31219e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print all diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0ec583d2-5f6e-49b3-9da8-da14c37585f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc_diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "3bf3ccbc-767e-4c9e-b185-f3ffca752fe3",
   "metadata": {},
   "outputs": [
    {
     "ename": "VersionConflict",
     "evalue": "Package pydantic is installed but has a version conflict:\n    Requirement: pydantic<3,>=2\n    Installed: 1.10.4\nThis package is required for trulens_eval. Please resolve the conflict by\ninstalling a compatible version with:\n\n    ```bash\n    pip install 'pydantic<3,>=2'\n    ```\n\nIf you are running trulens_eval in a notebook, you may need to restart the\nkernel after resolving the conflict. If your distribution is in a bad place\nbeyond this package, you may need to reinstall trulens_eval so that all of the\ndependencies get installed and hopefully corrected:\n    \n    ```bash\n    pip uninstall -y trulens_eval\n    pip install trulens_eval\n    ```\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mVersionConflict\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[120], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtrulens_eval\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/trulens_eval/__init__.py:98\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;66;03m# This check is intentionally done ahead of the other imports as we want to\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;66;03m# print out a nice warning/error before an import error happens further down\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;66;03m# this sequence.\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtrulens_eval\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimports\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_imports\n\u001b[0;32m---> 98\u001b[0m check_imports()\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtrulens_eval\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeedback\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeedback\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Feedback\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtrulens_eval\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeedback\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprovider\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Provider\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/trulens_eval/utils/imports.py:220\u001b[0m, in \u001b[0;36mcheck_imports\u001b[0;34m(ignore_version_mismatch)\u001b[0m\n\u001b[1;32m    217\u001b[0m message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m MESSAGE_FRAGMENT_VERSION_MISMATCH_PIP\u001b[38;5;241m.\u001b[39mformat(req\u001b[38;5;241m=\u001b[39mreq)\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m is_optional) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m ignore_version_mismatch):\n\u001b[0;32m--> 220\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m VersionConflict(message)\n\u001b[1;32m    222\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(message)\n",
      "\u001b[0;31mVersionConflict\u001b[0m: Package pydantic is installed but has a version conflict:\n    Requirement: pydantic<3,>=2\n    Installed: 1.10.4\nThis package is required for trulens_eval. Please resolve the conflict by\ninstalling a compatible version with:\n\n    ```bash\n    pip install 'pydantic<3,>=2'\n    ```\n\nIf you are running trulens_eval in a notebook, you may need to restart the\nkernel after resolving the conflict. If your distribution is in a bad place\nbeyond this package, you may need to reinstall trulens_eval so that all of the\ndependencies get installed and hopefully corrected:\n    \n    ```bash\n    pip uninstall -y trulens_eval\n    pip install trulens_eval\n    ```\n"
     ]
    }
   ],
   "source": [
    "import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6b8c6f-7c52-4017-a1d7-705fb3c9b257",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
